# ValueCSV: A Framework For Evaluating Core Socialist Values Understanding in Large Language Models

## Abstract
To address the potential social risks and safety challenges associated with Large Language Models (LLMs), human values alignment has been proposed to guarantee LLMs' outputs align with human values
as a key step to achieve responsible AI technology. However, current efforts to align LLMs with human values often rely on value theories such as Schwartzâ€™s value theory or moral foundation theory, which may not capture the full spectrum of diverse cultural or social values. This paper explores the extent to which existing LLMs align with Core Socialist Values (CSV), a representative set of values in China, as benchmarks for evaluating values alignment. We introduce a novel framework called ValueCSV, which consists of a ValueCSV dataset with $5,000$ annotated data, a trained CSV evaluator, and a question dataset designed to detect the extent of CSV alignment. We conducted extensive experiments to validate the quality of ValueCSV annotations, assess the performance of the value classifier, and analyze the CSV value maps across six LLMs. Our analysis reveals that these LLMs exhibit diverse value maps, with varying degrees of alignment across the 12 dimensions of CSV. Our framework is publicly available at [here](https://github.com/ValueCSV).

<!--![Corpus](assets/corpus_components.png)-->
<p align="center">
    <img src="https://github.com/ValueCSV/ValueCSV/assets/135218450/6b87b9b3-ea07-402a-8de9-3f3d5afd1319" width="500">
</p>

<br>

